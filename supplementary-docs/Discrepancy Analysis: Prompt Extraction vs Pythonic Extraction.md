# Discrepancy Analysis: Prompt Extraction vs Pythonic Extraction

**Context:**  
Both extractions were run over the same SilentStacks session record.  
- **Prompt-based extraction** (manual/interpretive by ChatGPT) yielded **â‰ˆ30 P0 failures**.  
- **Python-based extraction** (your JSON script) yielded **200+ P0 failures**.  

This document explains **why the counts diverge**.

---

## 1. Granularity of Extraction
- **Prompt extraction:** Groups related issues into **one P0**.  
  - Example: â€œMarkdown wrapping missingâ€ logged once, even if it happened 10+ times.  
- **Python extraction:** Treats **every occurrence** as its own P0.  
  - Same wrapper error appearing on three dates = three P0s.  

**Impact:** Python output much higher.

---

## 2. Triggering Logic
- **Prompt extraction:** Interpretive â€” only counts failures when clearly described in session narrative.  
- **Python extraction:** Rule-based â€” flags anything matching failure keywords (â€œmissing,â€ â€œnot wrapped,â€ â€œincompleteâ€).  

**Impact:** Script captures more subtle or repetitive failures.

---

## 3. Session Coverage
- **Prompt extraction:** Focused on ~20â€“25 visible sessions in record.  
- **Python extraction:** Parsed **all sub-entries** inside sessions (8â€“12 per session).  

**Impact:** Python produces >200 entries.

---

## 4. Treatment of Repeats
- **Prompt extraction:** Collapses repeats into **one canonical failure type**.  
  - â€œMarkdown wrapper missing (recurring)â€ â†’ logged once.  
- **Python extraction:** Logs repeats separately.  
  - Same wrapper issue on 08-20, 08-23, 08-25 = three distinct P0s.  

**Impact:** Higher counts in JSON.

---

## 5. Status Resolution
- **Prompt extraction:** Sometimes omits later repeats if marked âœ… Fixed.  
- **Python extraction:** Still logs repeats even if previously â€œfixed.â€  

**Impact:** Inflation of count in JSON.

---

## 6. Summary Table

| Aspect                | Prompt Extraction | Python Extraction |
|------------------------|------------------|------------------|
| Granularity           | Consolidated â€œtypesâ€ | Individual â€œinstancesâ€ |
| Triggering Logic      | Interpretive | Rule-based |
| Session Coverage      | Top-level sessions | Sub-entries + all repeats |
| Treatment of Repeats  | Collapsed | Counted each time |
| Status Handling       | Deduplicated if fixed | Logs all regardless |

---

## âœ… Conclusion
- **Both extractions are correct**, but they measure **different things**:  
  - Prompt = **unique failure modes (taxonomy)**  
  - Python = **all recorded occurrences (logbook)**  
- Discrepancy (â‰ˆ30 vs 200+) arises from **aggregation vs granularity**.

---

## ğŸ“Œ Next Step (if desired)
To reconcile:
- Collapse JSON into **unique failure types** â†’ should approach ~30.  
- Expand prompt extraction into **all occurrences** â†’ should approach 200+.  
